{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa5a327",
   "metadata": {},
   "source": [
    "# Identifying Disaster Tweets\n",
    " \n",
    "I apply machine learning techniques on Twitter data to identify which tweets relate to genuine disasters. This could be useful, for example, for emergency services or news agencies.\n",
    "\n",
    "### What am I predicting?\n",
    "\n",
    "Whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea94ae",
   "metadata": {},
   "source": [
    "\n",
    "### What should I expect the data format to be?\n",
    "\n",
    "Each sample in the train and test set has the following information:\n",
    "\n",
    "- The text of a tweet\n",
    "- A keyword from that tweet (although this may be blank)\n",
    "- The location the tweet was sent from (may also be blank)\n",
    "\n",
    "### Files\n",
    "\n",
    "- train.csv \n",
    "- test.csv \n",
    "\n",
    "### Columns\n",
    "\n",
    "- id - a unique identifier for each tweet\n",
    "- text - the text of the tweet\n",
    "- location - the location the tweet was sent from (may be blank)\n",
    "- keyword - a particular keyword from the tweet (may be blank)\n",
    "- target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a64bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, model_selection, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14f9a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ccec4",
   "metadata": {},
   "source": [
    "## K Most Occuring Words Sorted by their Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add2b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "  \n",
    "data_set = train_df[\"text\"] + \" \"\n",
    "data_set = data_set.str.cat()\n",
    "  \n",
    "# split() returns list of all the words in the string\n",
    "split_it = data_set.split()\n",
    "  \n",
    "# Pass the split_it list to instance of Counter class.\n",
    "Counter = Counter(split_it)\n",
    "  \n",
    "# most_common() produces k frequently encountered\n",
    "# input values and their respective counts.\n",
    "\n",
    "vocabulary_size = 10000\n",
    "most_occuring = Counter.most_common(vocabulary_size)\n",
    "\n",
    "vocab = [word for (word, count) in most_occuring]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f14f035",
   "metadata": {},
   "source": [
    "# Vectorize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58b7266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer converts a collection of text documents to a matrix of token counts\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer(vocabulary=vocab)\n",
    "\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "# note that we're NOT using .fit_transform() for test data. Using just .transform() makes sure\n",
    "# that the tokens in the train vectors are the only ones mapped to the test vectors - \n",
    "# i.e. that the train and test vectors use the same set of tokens.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_vectors.todense(), train_df[\"target\"], \n",
    "                                                   test_size=0.33, random_state=42)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3d0f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdQAAAHUCAYAAACDJ9lsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXVklEQVR4nO3dYaxkZ3kf8P9jX2xgt+BdWjbEdosRDsiyRElWLIiqQnHWISkNWSliidLKioz8oWlD4kTEzZdQVZGCFEFQWqeycCI+oAA1uKAoSrVyQEqldIUdoxJwKJZTg60FO62BClUJNm8/3Mlm9+5d37lz3zNzzszvJ1l3z9w7c977zpn795nnOe9Uay0AwMFcseoBAMA6EKgA0IFABYAOBCoAdCBQAaADgQoAHRwoUKvqrVX15ap6tKru6jUoAJiaWvQ61Kq6Msn/THIyyRNJPpfkp1trX+o3PACYhq0D3PcNSR5trT2WJFX10SRvT3LZQL36ihe1Q1e85Pz2M889dYDdA8BK/FVr7R/svPEggXptkq9dsP1EkhPPd4dDV7wktx4+fX77Y9+6+wC7B4BVeO7x3W49SKDOparuSHJHkry4/t7QuwOAlThIU9KTSa6/YPu62W0Xaa3d01o73lo7fvUVLzrA7gBgvA4SqJ9LcmNV3VBVVyV5Z5JP9xkWAEzLwm/5ttaerap/neS/Jrkyye+21r7YbWQAMCEHqqG21v4wyR92GgsATJaVkgCgA4EKAB0svFLSQjuratvlVgCYquceaq0d33mrM1QA6ECgAkAHAhUAOhh86cEL3XjoSO6++Zbz2yfP3r/nfU6/9F9dtP2u15675GfmeZy9HndZ6wrv3G+vfa/q94FVG+o1BfvlDBUAOhCoANCBQAWADkZ3HepetcDd6iU7Ta1+stfvNLXfh8WMuQ6uTjkf87QpXIcKAIMRqADQgUAFgA4EKgB0MLqmpCGsYyMTjJ0GHdaXpiQAGIxABYAOBCoAdLARNVQA6EcNFQAGI1ABoAOBCgAdLPUDxoH59bqOc8yL7tOP53n1nKECQAcCFQA6EKgA0IFABYAOlrqwww9df0X70zuvPr999Z3f3fdjTH2h+0UaTYZaZHzqTQyLjH/qvzMsyocV9GRhBwAYjEAFgA4EKgB0sLGL46ulTY/nDBgHNVQAGIxABYAOBCoAdLCxNdSd1OcAmI8aKgAMRqACQAcCFQA6EKgA0MFSm5KObh1rtx4+fX6712LmGooAWB5NSQAwGIEKAB0IVADoYHQLO6x7PXRZH/K7jh8mvO7HxrKs47EBy6WGCgCDEagA0IFABYAOBCoAdDC6piSWR5MPMFbj/vukKQkABiNQAaADgQoAHYx+cfyhDPX+/Ljf939+LvifnikfbzBdaqgAMBiBCgAdCFQA6GAtrkNVR+Jyehwbjq/NtG7Pux6JntRQAWAwAhUAOhCoANCBQAWADkbXlLRb4fxCiui7W7cGCpgijT+bQlMSAAxGoAJABwIVADoYfQ11qPqDmuPqzFNnUosCxksNFQAGI1ABoAOBCgAdLLWGevz4q9rZz/3789tbV9y2tH0D7Ic+Cy5PDRUABiNQAaADgQoAHQhUAOhga5k7e+zz38nPHDn7vD+zVyPAKi/4H3OTwlBjG/PvvNO6LQYx1O+zrHka0/OxyHE85WOH1XCGCgAd7BmoVXV9VX2mqr5UVV+sqnfPbj9aVWeq6iuzr0eGHy4AjNM8Z6jPJvml1tpNSd6Y5Oeq6qYkdyV5oLV2Y5IHZtsAsJH2vbBDVX0qyX+Y/feW1tq5qnpFks+21l6zx333XBwfAMatw8IOVfXKJK9PcjbJsdbaudm3vp7k2EGHCABTNXeXb1UdTvKJJL/QWvt2VZ3/XmutbZ997nq/O5LccdCBAsCYzXWGWlUvyHaYfqS19snZzd+YvdWb2dendrtva+2e1trx3U6PAWBd7HmGWtunovcmeaS19v4LvvXpJLcl+Y3Z10/t9Vg3HjqSu2++5fz2ybP373e8u1rkGrMpXV+5LGO6bnAeZ06cumi71/EEm8rfxYOZ5y3fNyf5l0m+UFWfn932q9kO0o9X1e1JHk/yjkFGCAATsGegttb+W5K6zLdvucztALBRrJQEAB0IVADoYN8LOxxoZxZ2GIxmAoBl6bCwAwCwO4EKAB0IVADoYPQ11N0WG9hJvRD6UpOfHs/ZMqmhAsBgBCoAdCBQAaCDydVQh6oL9NrPEOPttWj9ui0mP+aa0VC1/zH/zlMytQ+CYGzPmRoqAAxGoAJABwIVADoQqADQwVKbko5uHWu3Hj59flsTwO40nsDqeR1yeZqSAGAwAhUAOhCoANDB1qoHsNOq6ha99ttj8YRV1WrGdeH0pfZ6jsY+flZnkdelY4f9coYKAB0IVADoQKACQAejWxx/aovhwzzUd2GduA4VAAYjUAGgA4EKAB0IVADoYHRNSTtNvXlo6uNfRI/FLQDGS1MSAAxGoAJABwIVADoYfQ11p0UukN/tPvt9jLEbU612TGPpYd1+H+Cg1FABYDACFQA6EKgA0MHkaqgwRuqssEnUUAFgMAIVADoQqADQgUAFgA6W2pR0dOtYu/Xw6fPbGje2aWi51CILeMDleI3Rl6YkABiMQAWADgQqAHQwuhrqXgvZz3Mf9RGGtAn1Xa8peD5qqAAwGIEKAB0IVADoQKACQAej/7SZvZqUEg0T0JumJHg+mpIAYDACFQA6EKgA0MHWqgewX2o5MDyvM9g/Z6gA0IFABYAOBCoAdDD661B32oSFyVdlqLntdU3jIo8z5espHeswVq5DBYDBCFQA6ECgAkAHAhUAOhhdU9KUm0jGztwOp8fcen6WR8MXB6MpCQAGI1ABoAOBCgAdjK6GCgDjpoYKAIMRqADQgUAFgA5G/wHjrs2bHs8ZsImcoQJABwIVADoQqADQgUAFgA4s7DACmnimz3O4mTzvm8rCDgAwmLkDtaqurKqHq+oPZts3VNXZqnq0qj5WVVcNN0wAGLf9nKG+O8kjF2y/L8kHWmuvTvJMktt7DgwApmSuGmpVXZfkw0l+PcmdSf55kqeTfF9r7dmqelOS97bWfnSPx9n3B4zvtFuNQh3jUmP6AOWdY3nXa89d8jMnz96/rOEAHNDBaqi/leQ9Sb43235Zkm+21p6dbT+R5NqDDhEApmrPQK2qtyV5qrX20CI7qKo7qurBqnpwkfsDwBTMs5bvm5P8RFX9eJIXJnlJkg8muaaqtmZnqdcleXK3O7fW7klyT/K3b/kCwPrZ13WoVfWWJL/cWntbVf3nJJ9orX20qv5Tkv/RWnveIt0mXoeqvguwbvpfh/orSe6sqkezXVO99wCPBQCTtq+Pb2utfTbJZ2f/fizJG/oPCQCmx0pJANCBQAWADvb1lu9BHbny5bn18Onz24ss0jCmBQtgXo5bWH/OUAGgA4EKAB0IVADowAeM78O6L9Kgzrdc+gVgqnzAOAAMRqACQAcCFQA6GF0Nda8PGJ/HInWmXvXRMydOXbS984Oz1cU4iHWv48OyLfaaUkMFgMEIVADoQKACQAcCFQA6GF1T0k6aMAAYF01JADAYgQoAHQhUAOhgqTXUo1vH2l4fML6XRRZGWOZiCmq+wCpM+W/P9Ba8UUMFgMEIVADoQKACQAdLraH+0PVXtD+98+rz21ff+d0977PIYvnjfu99/8ZeN97LKms7U64rAWOlhgoAgxGoANCBQAWADgQqAHQwusXxz5w4ddH2ybP3X7Q9T5PSujWejKnBaEwWaTgac5PSJh7b9DPmY3v9aEoCgMEIVADoQKACQAejXxxfXQCAcVFDBYDBCFQA6ECgAkAHo7sOdRHqrAAsjxoqAAxGoAJABwIVADoQqADQwVo0JQHA8mhKAoDBCFQA6ECgAkAHW6sewH6t8sO2p76AxNTH38Oy5sBcw+ZxhgoAHQhUAOhAoAJABwIVADoY3cIOmkYutcpGrFXZxN8ZmAoLOwDAYAQqAHQgUAGgg9HVUIegHgdAP2qoADAYgQoAHQhUAOhg9DXUea4X/ev3v+Ci7avv/O7+B9fJs9/78EXbW1fcduDHXKQGvAl14zMnTl20ffLs/SsaCfB8pnTd/3zUUAFgMAIVADoQqADQgUAFgA5G35S00yY02wAwZpqSAGAwAhUAOhCoANDB5GqocBDrd4E5sHxqqAAwGIEKAB0IVADoYGuZOzty5ctz6+HT57d3q1/tVeNa5ULxPepvQ41/qNrglGqO63aN8rr9PrDunKECQAcCFQA6EKgA0IFABYAOLOywQabUYLQJPB+ro+GLg7GwAwAMZq5Araprquq+qvqLqnqkqt5UVUer6kxVfWX29cjQgwWAsZr3DPWDSf6otfbaJK9L8kiSu5I80Fq7MckDs20A2Eh71lCr6qVJPp/kVe2CH66qLyd5S2vtXFW9IslnW2uv2eOxVlJDnXq9ZOrjXxbzNH2eQ1ZtvmNw8RrqDUmeTvJ7VfVwVX2oqg4lOdZaOzf7ma8nOba/YQPA+pgnULeS/GCS32mtvT7Jd7Lj7d3Zmeuup7pVdUdVPVhVDx50sAAwVvME6hNJnmitnZ1t35ftgP3G7K3ezL4+tdudW2v3tNaO73Z6DADrYq7rUKvqT5K8q7X25ap6b5JDs2/979bab1TVXUmOttbe83yPc3TrWDvo4vhjN8T4x7S4P8ujnghjtXsNdd5Pm/k3ST5SVVcleSzJz2b77PbjVXV7kseTvKPXUAFgauYK1Nba55Ps9pbtLV1HAwATZaUkAOhAoAJAB5NbHH8TGzXOnDh1yW0nz95/0fY8DUeakhZjbjfzdbcI87QpLI4PAIMRqADQgUAFgA4mV0PtZVU1LzWW+Zgn2J91r+OPixoqAAxGoAJABwIVADrY2BrqTuoPAMxHDRUABiNQAaADgQoAHQhUAOhgqU1JP3D4aLv75r/7CNWdC7zPY2oX/Gt22gyeZ5imxV67mpIAYDACFQA6EKgA0IGFHZZsajVgAHZSQwWAwQhUAOhAoAJAB6OvoZ45ceqi7UWuXQWAftRQAWAwAhUAOhCoANCBQAWADkbflAQA46IpCQAGI1ABoAOBCgAdbK16AD2M+cOdd1sMf6cxjXdKzC0wJs5QAaADgQoAHQhUAOjAdagAsC+uQwWAwQhUAOhAoAJABwIVADpYi4UdGJcxL7QBMBRnqADQgUAFgA4EKgB0MLqFHfZa8HwT63G7zckQ87Cs/bBNrflSjkGmwcIOADAYgQoAHQhUAOhAoAJAB6NrSmJ1NIQAzENTEgAMRqACQAcCFQA6WIsaqgvkAVgeNVQAGIxABYAOBCoAdLAWNVQAWB41VAAYjEAFgA4EKgB0IFABoIOtVQ9gVaa0GMQmLFq/yPOx27zsZd3mjfmM6fU+prHQlzNUAOhAoAJABwIVADqwsAPs0ybUtFHr5PlY2AEABiNQAaADgQoAHaihAsC+qKECwGAEKgB0IFABoAOBCgAdTG5x/FVeVO9C78WYt+GY2/mYJ5bBGSoAdDBXoFbVL1bVF6vqz6vq96vqhVV1Q1WdrapHq+pjVXXV0IMFgLHaM1Cr6tokP5/keGvt5mxfSPrOJO9L8oHW2quTPJPk9iEHCgBjtufCDrNA/e9JXpfk20n+S5LfTvKRJN/XWnu2qt6U5L2ttR/d47Es7ADAxC24sENr7ckkv5nkq0nOJflWkoeSfLO19uzsx55Icm2/wQLAtMzzlu+RJG9PckOS709yKMlb591BVd1RVQ9W1YMLjxIARm6ey2Z+JMlfttaeTpKq+mSSNye5pqq2Zmep1yV5crc7t9buSXLP7L7LWzgYAJZonkD9apI3VtWLk/y/JLckeTDJZ5L8VJKPJrktyaf2eqAjV748tx4+fX7btWBweT7IHKZlnhrq2ST3JfmzJF+Y3eeeJL+S5M6qejTJy5LcO+A4AWDU5lopqbX2a0l+bcfNjyV5Q/cRAcAEWSkJADoQqADQwVIXx3/muaf2bKpY1iLW9jMui4x/6r8zfWjeYiycoQJABwIVADoQqADQwZ6L43fd2QKL46uTbQbPMxyM19AyLbg4PgCwN4EKAB0IVADoYPQ1VNaP6waBaVNDBYDBCFQA6ECgAkAHAhUAOtCUBCOleQvGSlMSAAxGoAJABwIVADoYXQ31zIlTF22fPHv/kEPalzEtPj2msQCLUyufIjVUABiMQAWADgQqAHQwuhrqJhpLPXS3Ws5OY67tqEUNNwfmdndjee2ybGqoADAYgQoAHQhUAOhAoAJAB6NrSlr3Iv8qmzsWmdt1fz6Gsm7zpikJLqQpCQAGI1ABoAOBCgAdLLWGenTrWLv18Onz22owAEyPGioADEagAkAHAhUAOnAd6giZA4AxU0MFgMEIVADoQKACQAcCFQA6GF1T0l42cZHuTfydYVN4fY/LfM+HpiQAGIxABYAOBCoAdDC6Guq6L2qgXrK7Hs/71Od23Y99dnfmxKlLbjt59v4VjITLufS1+dtqqAAwFIEKAB0IVADoQKACQAdLbUo6unWs3Xr49PnteZouNGqslvkH2MnCDgAwGIEKAB0IVADoYKk11B84fLTdffMt57d7Xbw85jrfmMa228IHFxrTvG2CZR0bYzoGYWwWe32ooQLAYAQqAHQgUAGgA4vjA6yBKf/tnN4HW6ihAsBgBCoAdCBQAaADgQoAHYyuKWkI0yt4MzVTbggB9ktTEgAMRqACQAcCFQA6GN0HjO9Vizpz4tQl91lkkX01r80wludZHR/WiRoqAAxGoAJABwIVADrYiOtQ19FYaoO7GfPYAA5ODRUABiNQAaADgQoAHQhUAOhAUxIA7IumJAAYjEAFgA4EKgB0sLXk/f1V8tzjSf7+9r8ZgLkdjrkdjrkdjrnt7x/tduNSm5LO77Tqwd0KuhycuR2OuR2OuR2OuV0eb/kCQAcCFQA6WFWg3rOi/W4Cczscczscczscc7skK6mhAsC68ZYvAHSw1ECtqrdW1Zer6tGqumuZ+143VXV9VX2mqr5UVV+sqnfPbj9aVWeq6iuzr0dWPdapqqorq+rhqvqD2fYNVXV2dvx+rKquWvUYp6iqrqmq+6rqL6rqkap6k+O2j6r6xdnfgz+vqt+vqhc6bpdnaYFaVVcm+Y9JfizJTUl+uqpuWtb+19CzSX6ptXZTkjcm+bnZfN6V5IHW2o1JHphts5h3J3nkgu33JflAa+3VSZ5JcvtKRjV9H0zyR6211yZ5Xbbn2HF7QFV1bZKfT3K8tXZzthdOf2cct0uzzDPUNyR5tLX2WGvtb5J8NMnbl7j/tdJaO9da+7PZv/9vtv8oXZvtOf3w7Mc+nOQnVzLAiauq65L8syQfmm1Xkh9Oct/sR8ztAqrqpUn+aZJ7k6S19jettW/GcdvLVpIXVdVWkhcnORfH7dIsM1CvTfK1C7afmN3GAVXVK5O8PsnZJMdaa+dm3/p6kmOrGtfE/VaS9yT53mz7ZUm+2Vp7drbt+F3MDUmeTvJ7s7fTP1RVh+K4PbDW2pNJfjPJV7MdpN9K8lAct0ujKWniqupwkk8k+YXW2rcv/F7bbuHWxr1PVfW2JE+11h5a9VjW0FaSH0zyO6211yf5Tna8veu4Xcys7vz2bP9Py/cnOZTkrSsd1IZZZqA+meT6C7avm93GgqrqBdkO04+01j45u/kbVfWK2fdfkeSpVY1vwt6c5Ceq6n9luzTxw9mu+10zeystcfwu6okkT7TWzs6278t2wDpuD+5Hkvxla+3p1tp3k3wy28ey43ZJlhmon0ty46zj7KpsF8s/vcT9r5VZTe/eJI+01t5/wbc+neS22b9vS/KpZY9t6lpr/7a1dl1r7ZXZPk7/uLX2M0k+k+SnZj9mbhfQWvt6kq9V1WtmN92S5Etx3Pbw1SRvrKoXz/4+/O3cOm6XZKkLO1TVj2e7NnVlkt9trf360na+ZqrqnyT5kyRfyN/V+X4123XUjyf5h0keT/KO1tr/Wckg10BVvSXJL7fW3lZVr8r2GevRJA8n+Rettb9e4fAmqar+cbabva5K8liSn832/9w7bg+oqv5dktPZvgrg4STvynbN1HG7BFZKAoAONCUBQAcCFQA6EKgA0IFABYAOBCoAdCBQAaADgQoAHQhUAOjg/wNb5arWlmsClwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.imshow(x_train[:100, :100], cmap=\"inferno\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc3ab2",
   "metadata": {},
   "source": [
    "# RidgeClassifier (Kaggle example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e93bb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.7704\n",
      "f1 is: 0.7225\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, metrics\n",
    "\n",
    "## Our vectors are really big, so we want to push our model's weights toward 0 \n",
    "## without completely discounting different words - \n",
    "## ridge regression is a good way to do this.\n",
    "clf = linear_model.RidgeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy is: \" + f\"{accuracy:.04f}\")\n",
    "\n",
    "f1 = metrics.f1_score(y_test, y_pred)\n",
    "print(\"f1 is: \" + f\"{f1:.04f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d108f7",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy is: \" + f\"{accuracy:.04f}\")\n",
    "\n",
    "f1 = metrics.f1_score(y_test, y_pred)\n",
    "print(\"f1 is: \" + f\"{f1:.04f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b716683",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418cf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "clf = DecisionTreeClassifier(max_leaf_nodes=10) #This takes too long without some limit\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy is: \" + f\"{accuracy:.04f}\")\n",
    "\n",
    "f1 = metrics.f1_score(y_test, y_pred)\n",
    "print(\"f1 is: \" + f\"{f1:.04f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9150a",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ba2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs vectorized data as input\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation=\"relu\", input_shape=(vocabulary_size, )))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=20,\n",
    "    batch_size=500,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316daf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(model.history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy with Simple Neural Network\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(model.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Loss with Simple Neural Network\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc82ec",
   "metadata": {},
   "source": [
    "# Neural Networks with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41940c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df[\"text\"]\n",
    "y_train = train_df[\"target\"]\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1089ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working out word length of tweets\n",
    "\n",
    "lengths = [len(t.split(' ')) for t in train_df[\"text\"]]\n",
    "\n",
    "plt.hist(lengths, bins=len(set(lengths)))\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.title('Word-Length of Tweets')\n",
    "plt.show()\n",
    "\n",
    "# the chart shows that 30 is a reasonable sequence length\n",
    "\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train_tokenized = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "x_train_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60744c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding and Truncating\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "x_train_padded = preprocessing.sequence.pad_sequences(\n",
    "    x_train_tokenized,\n",
    "    maxlen=sequence_length,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b72c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "embedding_size = 16\n",
    "model.add(layers.Embedding(vocabulary_size, embedding_size, input_length=sequence_length))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_padded, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=500,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d73d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(model.history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy with Neural Network + Embedding\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(model.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Loss with Neural Network + Embedding\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d12b3d",
   "metadata": {},
   "source": [
    "# Neural Networks with Embedding & LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25040d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(vocabulary_size, embedding_size, input_length=sequence_length))\n",
    "model.add(layers.LSTM(32, return_sequences=True))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_padded, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=500,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(model.history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Neural Network with Embedding & LSTM\")\n",
    "plt.title(\"Accuracy with Neural Network + Embedding & LSTM\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(model.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Loss with Neural Network + Embedding & LSTM\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
